  version: '2.1'
  services:
    zoo1:
      image: confluentinc/cp-zookeeper:6.0.1
      hostname: zoo1
      container_name: zoo1
      networks:
        - localnet
      ports:
        - "2181:2181"
      environment:
        ZOOKEEPER_CLIENT_PORT: 2181
        ZOOKEEPER_TICK_TIME: 2000

    kafka1:
      image: confluentinc/cp-kafka:6.0.1
      hostname: kafka1
      container_name: kafka-broker-1
      networks:
        - localnet
      ports:
        - "9092:9092"
      environment:
        KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka1:19092,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092
        KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
        KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
        KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181"
        KAFKA_BROKER_ID: 1
        KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      depends_on:
        - zoo1

    kafka2:
      image: confluentinc/cp-kafka:6.0.1
      hostname: kafka2
      container_name: kafka-broker-2
      networks:
        - localnet
      ports:
        - "9093:9093"
      environment:
        KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka2:19093,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9093
        KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
        KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
        KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181"
        KAFKA_BROKER_ID: 2
        KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      depends_on:
        - zoo1

    kafka3:
      image: confluentinc/cp-kafka:6.0.1
      hostname: kafka3
      container_name: kafka-broker-3
      networks:
        - localnet
      ports:
        - "9094:9094"
      environment:
        KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka3:19094,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9094
        KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
        KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
        KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181"
        KAFKA_BROKER_ID: 3
        KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      depends_on:
        - zoo1


    schema-registry:
      image: confluentinc/cp-schema-registry:6.0.1
      hostname: schema-registry
      container_name: schema-registry
      networks:
        - localnet
      depends_on:
        - kafka1
        - kafka2
        - kafka3
      ports:
        - "8081:8081"
      environment:
        SCHEMA_REGISTRY_HOST_NAME: schema-registry
        SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka1:19092,kafka2:19093,kafka3:19094
        SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081

    connect:
      image: cnfldemos/kafka-connect-datagen:0.4.0-6.0.1
      hostname: connect
      container_name: connect
      networks:
        - localnet
      depends_on:
        - kafka1
        - kafka2
        - kafka3
        - schema-registry
      ports:
        - "8083:8083"
      environment:
        CONNECT_BOOTSTRAP_SERVERS: kafka1:19092,kafka2:19093,kafka3:19094
        CONNECT_REST_ADVERTISED_HOST_NAME: connect
        CONNECT_REST_PORT: 8083
        CONNECT_GROUP_ID: compose-connect-group
        CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
        CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
        CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
        CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
        CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
        CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
        CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
        CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
        CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
        CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
        CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components,/home/appuser/connectors"
        CONNECT_LOG4J_LOGGERS: org.apache.zookeeper=ERROR,org.I0Itec.zkclient=ERROR,org.reflections=ERROR
      volumes:
        - ./host-volume/connectors:/home/appuser/connectors

    ksqldb-server:
      image: confluentinc/cp-ksqldb-server:6.0.1
      hostname: ksqldb-server
      container_name: ksqldb-server
      networks:
        - localnet
      depends_on:
        - kafka1
        - kafka2
        - kafka3
        - connect
      ports:
        - "8088:8088"
      environment:
        KSQL_CONFIG_DIR: "/etc/ksql"
        KSQL_BOOTSTRAP_SERVERS: kafka1:19092,kafka2:19093,kafka3:19094
        KSQL_HOST_NAME: ksqldb-server
        KSQL_LISTENERS: "http://0.0.0.0:8088"
        KSQL_CACHE_MAX_BYTES_BUFFERING: 0
        KSQL_KSQL_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
        KSQL_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
        KSQL_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
        KSQL_KSQL_CONNECT_URL: "http://connect:8083"
        KSQL_KSQL_LOGGING_PROCESSING_TOPIC_REPLICATION_FACTOR: 1
        KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: 'true'
        KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: 'true'

    ksqldb-cli:
      image: confluentinc/cp-ksqldb-cli:6.0.1
      container_name: ksqldb-cli
      depends_on:
        - kafka1
        - kafka2
        - kafka3
        - connect
        - ksqldb-server
      entrypoint: /bin/sh
      tty: true

    ksql-datagen:
      image: confluentinc/ksqldb-examples:6.0.1
      hostname: ksql-datagen
      container_name: ksql-datagen
      networks:
        - localnet
      depends_on:
        - ksqldb-server
        - kafka1
        - kafka2
        - kafka3
        - schema-registry
        - connect
      command: "bash -c 'echo Waiting for Kafka to be ready... && \
                         cub kafka-ready -b kafka1:19092,kafka2:19093,kafka3:19094 1 40 && \
                         echo Waiting for Confluent Schema Registry to be ready... && \
                         cub sr-ready schema-registry 8081 40 && \
                         echo Waiting a few seconds for topic creation to finish... && \
                         sleep 11 && \
                         tail -f /dev/null'"
      environment:
        KSQL_CONFIG_DIR: "/etc/ksql"
        STREAMS_BOOTSTRAP_SERVERS: kafka1:19092,kafka2:19093,kafka3:19094
        STREAMS_SCHEMA_REGISTRY_HOST: schema-registry
        STREAMS_SCHEMA_REGISTRY_PORT: 8081

    rest-proxy:
      image: confluentinc/cp-kafka-rest:6.0.1
      depends_on:
        - kafka1
        - kafka2
        - kafka3
        - schema-registry
      ports:
        - 8082:8082
      hostname: rest-proxy
      container_name: rest-proxy
      networks:
        - localnet
      environment:
        KAFKA_REST_HOST_NAME: rest-proxy
        KAFKA_REST_BOOTSTRAP_SERVERS: kafka1:19092,kafka2:19093,kafka3:19094
        KAFKA_REST_LISTENERS: "http://0.0.0.0:8082"
        KAFKA_REST_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'

    mongo1:
      image: "mongo:4.0-xenial"
      hostname: mongo1
      container_name: mongo1
      command: --replSet rs0 --smallfiles --oplogSize 128
      volumes:
        - rs1:/data/db
      networks:
        - localnet
      ports:
        - "27017:27017"
      restart: always
    mongo2:
      image: "mongo:4.0-xenial"
      hostname: mongo2
      container_name: mongo2
      command: --replSet rs0 --smallfiles --oplogSize 128
      volumes:
        - rs2:/data/db
      networks:
        - localnet
      ports:
        - "27018:27017"
      restart: always
    mongo3:
      image: "mongo:4.0-xenial"
      hostname: mongo3
      container_name: mongo3
      command: --replSet rs0 --smallfiles --oplogSize 128
      volumes:
        - rs3:/data/db
      networks:
        - localnet
      ports:
        - "27019:27017"
      restart: always

  networks:
    localnet:
      attachable: true

  volumes:
    rs1:
    rs2:
    rs3: